{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Experiment\n",
    "\n",
    "**Goal:** Learn how to create embeddings with OpenAI API.\n",
    "\n",
    "**What we'll do:**\n",
    "1. Connect to OpenAI API\n",
    "2. Create embedding for a single text\n",
    "3. Compare embeddings of similar vs different texts\n",
    "4. Batch embed multiple texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries & Load API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"‚úÖ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Embedding for Single Text\n",
    "\n",
    "Let's create an embedding for a simple automotive text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text about CAN protocol\n",
    "text = \"CAN protocol is used in automotive networks for communication between ECUs\"\n",
    "\n",
    "# Create embedding\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=text\n",
    ")\n",
    "\n",
    "# Extract embedding vector\n",
    "embedding = response.data[0].embedding\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"\\nEmbedding dimensions: {len(embedding)}\")\n",
    "print(f\"First 10 values: {embedding[:10]}\")\n",
    "print(f\"\\nEmbedding type: {type(embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compare Similar vs Different Texts\n",
    "\n",
    "**Cosine Similarity:**\n",
    "- Measures how similar two vectors are\n",
    "- Range: -1 to 1\n",
    "- 1 = identical, 0 = unrelated, -1 = opposite\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "similarity = (A ¬∑ B) / (||A|| * ||B||)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Test texts\n",
    "text1 = \"CAN protocol is used in automotive networks\"\n",
    "text2 = \"Controller Area Network enables vehicle communication\"  # Similar!\n",
    "text3 = \"Apple pie recipe with cinnamon\"  # Different!\n",
    "\n",
    "# Create embeddings\n",
    "emb1 = client.embeddings.create(model=\"text-embedding-3-small\", input=text1).data[0].embedding\n",
    "emb2 = client.embeddings.create(model=\"text-embedding-3-small\", input=text2).data[0].embedding\n",
    "emb3 = client.embeddings.create(model=\"text-embedding-3-small\", input=text3).data[0].embedding\n",
    "\n",
    "# Calculate similarities\n",
    "sim_1_2 = cosine_similarity(emb1, emb2)\n",
    "sim_1_3 = cosine_similarity(emb1, emb3)\n",
    "\n",
    "print(\"Text 1:\", text1)\n",
    "print(\"Text 2:\", text2)\n",
    "print(\"Text 3:\", text3)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Similarity (Text 1 ‚Üî Text 2): {sim_1_2:.4f}  ‚Üê High! (similar topics)\")\n",
    "print(f\"Similarity (Text 1 ‚Üî Text 3): {sim_1_3:.4f}  ‚Üê Low! (different topics)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Batch Embeddings\n",
    "\n",
    "**Why batch?**\n",
    "- More efficient (single API call)\n",
    "- Faster\n",
    "- Lower cost\n",
    "\n",
    "**Limit:** Max 2048 texts per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple texts\n",
    "texts = [\n",
    "    \"CAN bus uses twisted pair cables\",\n",
    "    \"OBD-II diagnostic connector in vehicles\",\n",
    "    \"Infotainment system user interface\",\n",
    "    \"Electronic Control Unit programming\",\n",
    "    \"Vehicle network architecture\"\n",
    "]\n",
    "\n",
    "# Batch embed\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=texts  # Pass list of texts\n",
    ")\n",
    "\n",
    "# Extract all embeddings\n",
    "embeddings = [item.embedding for item in response.data]\n",
    "\n",
    "print(f\"Embedded {len(texts)} texts in a single API call\")\n",
    "print(f\"Each embedding has {len(embeddings[0])} dimensions\")\n",
    "print(\"\\nTexts:\")\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"  {i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Real Chunk Embedding Test\n",
    "\n",
    "Let's embed a few real chunks from our PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a few chunks from our PDF loader\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.pdf_loader import load_pdfs_from_directory\n",
    "\n",
    "# Load chunks (limit to first 5 for testing)\n",
    "print(\"Loading PDF chunks...\")\n",
    "chunks = load_pdfs_from_directory(\"../data/automotive\")\n",
    "test_chunks = chunks[:5]\n",
    "\n",
    "print(f\"\\nEmbedding {len(test_chunks)} chunks...\")\n",
    "\n",
    "# Extract text from chunks\n",
    "chunk_texts = [chunk.page_content for chunk in test_chunks]\n",
    "\n",
    "# Create embeddings\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=chunk_texts\n",
    ")\n",
    "\n",
    "chunk_embeddings = [item.embedding for item in response.data]\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully embedded {len(chunk_embeddings)} chunks\")\n",
    "print(f\"‚úÖ Each embedding: {len(chunk_embeddings[0])} dimensions\")\n",
    "\n",
    "# Show first chunk\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"First Chunk Preview:\")\n",
    "print(\"=\"*60)\n",
    "print(test_chunks[0].page_content[:200] + \"...\")\n",
    "print(f\"\\nEmbedding (first 10 values): {chunk_embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Cost Estimation\n",
    "\n",
    "Let's estimate the cost for embedding all 635 chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Initialize tokenizer\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")  # OpenAI's tokenizer\n",
    "\n",
    "# Count tokens in all chunks\n",
    "total_tokens = 0\n",
    "for chunk in chunks:\n",
    "    tokens = encoding.encode(chunk.page_content)\n",
    "    total_tokens += len(tokens)\n",
    "\n",
    "# Cost calculation\n",
    "# text-embedding-3-small: $0.00002 per 1K tokens\n",
    "cost_per_1k = 0.00002\n",
    "total_cost = (total_tokens / 1000) * cost_per_1k\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Cost Estimation for Full Embedding\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(f\"Total tokens: {total_tokens:,}\")\n",
    "print(f\"Model: text-embedding-3-small\")\n",
    "print(f\"Cost per 1K tokens: ${cost_per_1k}\")\n",
    "print(f\"\\nüí∞ Estimated cost: ${total_cost:.4f}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ Very affordable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What you learned:**\n",
    "1. How to create embeddings with OpenAI API\n",
    "2. How to measure similarity with cosine similarity\n",
    "3. Batch embedding for efficiency\n",
    "4. Real chunk embedding works perfectly\n",
    "5. Cost is very low (~$0.01 for 635 chunks)\n",
    "\n",
    "**Next step:** Create `src/embeddings.py` with reusable functions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
