{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Loading & Chunking Experiment\n",
    "\n",
    "**Goal:** Learn how to load PDFs and split them into chunks for RAG system.\n",
    "\n",
    "**What we'll do:**\n",
    "1. Load a single PDF\n",
    "2. Inspect its structure\n",
    "3. Split into chunks\n",
    "4. Examine chunk metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries\n",
    "\n",
    "First, import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import these libraries\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load a Single PDF\n",
    "\n",
    "Let's start with the smallest PDF: `On-board Diagnostics.pdf` (1.5MB)\n",
    "\n",
    "**What PyPDFLoader does:**\n",
    "- Reads PDF file\n",
    "- Extracts text from each page\n",
    "- Returns a list of `Document` objects (1 per page)\n",
    "\n",
    "**Each Document has:**\n",
    "- `page_content`: The text\n",
    "- `metadata`: Info like page number, source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 pages\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load the PDF\n",
    "# 1. Define the path to the PDF\n",
    "pdf_path = \"../data/automotive/On-board Diagnostics.pdf\"\n",
    "\n",
    "# 2. Create a PyPDFLoader instance\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "# 3. Load the pages\n",
    "pages = loader.load()\n",
    "\n",
    "# 4. Print how many pages loaded\n",
    "print(f\"Loaded {len(pages)} pages\")\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Inspect the First Page\n",
    "\n",
    "Let's see what a single page looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata:\n",
      "{'source': '../data/automotive/On-board Diagnostics.pdf', 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Content preview:\n",
      "Various views of a \"MaxScan OE509\" – a\n",
      "fairly typical onboard diagnostics (OBD)\n",
      "scanner, 2015.\n",
      "On-board diagnostics\n",
      "On-board diagnostics (OBD) is a term referring to a\n",
      "vehicle's self-diagnostic and reporting capability. In the\n",
      "United States, this capability is a requirement to comply\n",
      "with federal emissions standards to detect failures that\n",
      "may increase the vehicle tailpipe emissions to more than\n",
      "150% of the standard to which it was originally\n",
      "certified.[1][2]\n",
      "OBD systems give the vehicle owner o\n",
      "\n",
      "Total characters: 3118\n"
     ]
    }
   ],
   "source": [
    "# TODO: Examine first page\n",
    "# 1. Get the first page\n",
    "first_page = pages[0]\n",
    "\n",
    "# 2. Print the metadata\n",
    "print(\"Metadata:\")\n",
    "print(first_page.metadata)\n",
    "\n",
    "# 3. Print first 500 characters of content\n",
    "print(\"\\nContent preview:\")\n",
    "print(first_page.page_content[:500])\n",
    "\n",
    "# 4. Print total character count\n",
    "print(f\"\\nTotal characters: {len(first_page.page_content)}\")\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split into Chunks\n",
    "\n",
    "**Why chunk?** \n",
    "- LLMs have token limits (GPT-3.5: ~4096 tokens)\n",
    "- A full PDF page might be too long\n",
    "- Smaller chunks = more precise retrieval\n",
    "\n",
    "**RecursiveCharacterTextSplitter:**\n",
    "- `chunk_size`: Max characters per chunk (1000 ≈ 150-200 words)\n",
    "- `chunk_overlap`: How many characters overlap between chunks (prevents splitting important context)\n",
    "\n",
    "**How it works:**\n",
    "1. Tries to split at paragraph breaks (`\\n\\n`)\n",
    "2. If still too big, tries newlines (`\\n`)\n",
    "3. If still too big, tries spaces\n",
    "4. Last resort: splits at exact character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 20 pages into 72 chunks\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create text splitter and split documents\n",
    "# 1. Create the splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "     chunk_size=1000,\n",
    "     chunk_overlap=200,\n",
    " )\n",
    "\n",
    "# 2. Split all pages into chunks\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "# 3. Print how many chunks created\n",
    "print(f\"Split {len(pages)} pages into {len(chunks)} chunks\")\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Examine a Few Chunks\n",
    "\n",
    "Let's see what the chunks look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Chunk 1\n",
      "============================================================\n",
      "Metadata: {'source': '../data/automotive/On-board Diagnostics.pdf', 'page': 0, 'page_label': '1'}\n",
      "Length: 996 characters\n",
      "\n",
      "Content:\n",
      "Various views of a \"MaxScan OE509\" – a\n",
      "fairly typical onboard diagnostics (OBD)\n",
      "scanner, 2015.\n",
      "On-board diagnostics\n",
      "On-board diagnostics (OBD) is a term referring to a\n",
      "vehicle's self-diagnostic and reporting capability. In the\n",
      "United States, this capability is a requirement to comply\n",
      "with federal emissions standards to detect failures that\n",
      "may increase the vehicle tailpipe emissions to more than\n",
      "150% of the standard to which it was originally\n",
      "certified.[1][2]\n",
      "OBD systems give the vehicle owner or repair technician\n",
      "access to the status of the various vehicle sub-systems. The\n",
      "amount of diagnostic information available via OBD has\n",
      "varied widely since its introduction in the early 1980s\n",
      "versions of onboard vehicle computers. Early versions of\n",
      "OBD would simply illuminate a tell-tale light if a problem\n",
      "was detected, but would not provide any information as to the nature of the problem. Modern OBD\n",
      "implementations use a standardized digital communications port to provide real-time data and\n",
      "\n",
      "============================================================\n",
      "Chunk 2\n",
      "============================================================\n",
      "Metadata: {'source': '../data/automotive/On-board Diagnostics.pdf', 'page': 0, 'page_label': '1'}\n",
      "Length: 957 characters\n",
      "\n",
      "Content:\n",
      "was detected, but would not provide any information as to the nature of the problem. Modern OBD\n",
      "implementations use a standardized digital communications port to provide real-time data and\n",
      "diagnostic trouble codes which allow malfunctions within the vehicle to be rapidly identified.\n",
      "1968: Volkswagen introduces the ﬁrst on-board computer system, in their fuel-injected Type 3\n",
      "models. This system is entirely analog with no diagnostic capabilities.\n",
      "1975: Bosch and Bendix EFI systems are adopted by major automotive manufacturers to\n",
      "improve tailpipe (exhaust) emissions. These systems are also analog, though some provide\n",
      "rudimentary diagnostic capability through factory tools, such as the Kent Moore J-25400,\n",
      "compatible with the Datsun 280Z, and the Cadillac Seville.\n",
      "1980: General Motors introduces the ﬁrst data link on their 1980 Cadillac Eldorado and Seville\n",
      "models. Diagnostic Trouble Codes (DTCs) are displayed through the electronic climate control\n",
      "\n",
      "============================================================\n",
      "Chunk 3\n",
      "============================================================\n",
      "Metadata: {'source': '../data/automotive/On-board Diagnostics.pdf', 'page': 0, 'page_label': '1'}\n",
      "Length: 959 characters\n",
      "\n",
      "Content:\n",
      "1980: General Motors introduces the ﬁrst data link on their 1980 Cadillac Eldorado and Seville\n",
      "models. Diagnostic Trouble Codes (DTCs) are displayed through the electronic climate control\n",
      "system's digital readout when in diagnostic mode.[ 3 ] \n",
      "1981: General Motors introduced its \"Computer Command Control\" system on all US\n",
      "passenger vehicles for model year 1981. Included in this system is a proprietary 5-pin ALDL\n",
      "that interfaces with the Engine Control Module (ECM) to initiate a diagnostic request and\n",
      "provide a serial data stream. The protocol communicates at 160 baud with Pulse-width\n",
      "modulation (PWM) signaling and monitors all engine management functions. It reports real-\n",
      "time sensor data, component overrides, and Diagnostic Trouble Codes. The speciﬁcation for\n",
      "this link is as deﬁned by GM's Emissions Control System Project Center document XDE-\n",
      "5024B.[ 4 ] [ 5 ] \n",
      "1982: RCA deﬁnes an analog STE/ICE (simpliﬁed test equipment for internal combustion\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print first 3 chunks\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Chunk {i+1}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Metadata: {chunk.metadata}\")\n",
    "    print(f\"Length: {len(chunk.page_content)} characters\")\n",
    "    print(f\"\\nContent:\\n{chunk.page_content}\")\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test Different Chunk Sizes\n",
    "\n",
    "Let's experiment with different chunk sizes to see the impact.\n",
    "\n",
    "**Trade-offs:**\n",
    "- **Larger chunks (2000+):** More context, fewer chunks, but might exceed token limit\n",
    "- **Smaller chunks (500):** More precise, but might lose context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size 500: 135 chunks created\n",
      "Chunk size 1000: 72 chunks created\n",
      "Chunk size 2000: 38 chunks created\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test different chunk sizes\n",
    "chunk_sizes = [500, 1000, 2000]\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=int(size * 0.2)  # 20% overlap\n",
    "    )\n",
    "    test_chunks = splitter.split_documents(pages)\n",
    "    print(f\"Chunk size {size}: {len(test_chunks)} chunks created\")\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load All PDFs from Directory\n",
    "\n",
    "Now let's load ALL PDFs from the automotive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDF files\n",
      "\n",
      "Loading: automotive_infotainment.pdf\n",
      "  - 62 pages → 136 chunks\n",
      "\n",
      "Loading: On-board Diagnostics.pdf\n",
      "  - 20 pages → 72 chunks\n",
      "\n",
      "Loading: CAN.pdf\n",
      "  - 167 pages → 427 chunks\n",
      "\n",
      "Total chunks: 635\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load all PDFs\n",
    "# 1. Get all PDF files\n",
    "pdf_dir = Path(\"../data/automotive\")\n",
    "pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF files\")\n",
    "\n",
    "# 2. Load and chunk each PDF\n",
    "all_chunks = []\n",
    "for pdf_path in pdf_files:\n",
    "    print(f\"\\nLoading: {pdf_path.name}\")\n",
    "    loader = PyPDFLoader(str(pdf_path))\n",
    "    pages = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(pages)\n",
    "    all_chunks.extend(chunks)\n",
    "    print(f\"  - {len(pages)} pages → {len(chunks)} chunks\")\n",
    "\n",
    "# 3. Print total\n",
    "print(f\"\\nTotal chunks: {len(all_chunks)}\")\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What you learned:**\n",
    "1. How to load PDFs with `PyPDFLoader`\n",
    "2. How to split documents into chunks with `RecursiveCharacterTextSplitter`\n",
    "3. How chunk size affects the number of chunks\n",
    "4. How to process multiple PDFs from a directory\n",
    "\n",
    "**Next step:** Move this logic to `src/pdf_loader.py` as a reusable function!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
